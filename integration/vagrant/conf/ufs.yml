# hadoop1 | hadoop2 | glusterfs | s3 | gcs
# If it is not specified, a default value is used.
# For AWS EC2, the default is s3; for Google Compute Engine, the default is gcs; for other
# providers, it is hadoop2.
Type:

Hadoop:
  # Hadoop version can be checked at
  # http://archive.apache.org/dist/hadoop/common/.
  #
  # Supported hadoop versions for Alluxio can be checked at
  # https://www.alluxio.io/download/.
  Version: 2.7.7
  # For some version of hadoop, profile is needed when compiling spark
  # https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version
  # e.x. 2.4 for hadoop 2.4.1
  # if you don't compile spark, this can be empty
  SparkProfile: 2.4

# Doc on AccessKeyID and SecretAccessKey:
# http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html
S3:
  # The bucket should be the name of an existing bucket (e.g. alluxiodata, not
  # s3://alluxiodata, s3n://alluxiodata, etc.)
  Bucket:

# Doc on accessKeyID and secretAccessKey:
# https://cloud.google.com/storage/docs/migrating#keys
GCS:
  # The bucket should be the name of an existing bucket (e.g. alluxiodata, not gs://alluxiodata)
  Bucket:

Swift:
  # The container should be the name of an existing container (e.g. alluxiodata, not swift://alluxiodata)
  Container:
