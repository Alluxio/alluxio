# hadoop1 | hadoop2 | glusterfs | s3 | gcs
# If it is not specified, a default value is used.
# For AWS EC2, the default is s3; for Google Compute Engine, the default is gcs; for other
# providers, it is hadoop2.
Type:

Hadoop:
  # apache: http://archive.apache.org/dist/hadoop/common/hadoop-${Version}/hadoop-${Version}.tar.gz
  # cdh: https://repository.cloudera.com/cloudera/cloudera-repos/org/apache/hadoop/hadoop-dist/${Version}/hadoop-dist-${Version}.tar.gz
  # apache | cdh
  Type: apache
  # e.x. 2.4.1, 2.0.0-cdh4.7.1 for hadoop2
  #      1.2.1 for hadoop1
  Version: 2.4.1
  # for some version of hadoop, profile is needed when compiling spark
  # https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version
  # e.x. 2.4 for hadoop 2.4.1
  # if you don't compile spark, this can be empty
  SparkProfile: 2.4

# Doc on AccessKeyID and SecretAccessKey:
# http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html
S3:
  # The bucket should be the name of an existing bucket (e.g. alluxiodata, not
  # s3://alluxiodata, s3n://alluxiodata, etc.)
  Bucket:

# Doc on accessKeyID and secretAccessKey:
# https://cloud.google.com/storage/docs/migrating#keys
GCS:
  # The bucket should be the name of an existing bucket (e.g. alluxiodata, not gs://alluxiodata)
  Bucket:
