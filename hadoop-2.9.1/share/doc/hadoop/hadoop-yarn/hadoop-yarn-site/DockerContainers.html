<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--
 | Generated by Apache Maven Doxia at 2018-04-16
 | Rendered using Apache Maven Stylus Skin 1.5
-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop 2.9.1 &#x2013; Launching Applications Using Docker Containers</title>
    <style type="text/css" media="all">
      @import url("./css/maven-base.css");
      @import url("./css/maven-theme.css");
      @import url("./css/site.css");
    </style>
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20180416" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="http://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="http://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                   <div class="xleft">
                          <a href="http://www.apache.org/" class="externalLink">Apache</a>
        &gt;
                  <a href="http://hadoop.apache.org/" class="externalLink">Hadoop</a>
        &gt;
                  <a href="../index.html">Apache Hadoop YARN</a>
        &gt;
                  <a href="index.html">Apache Hadoop 2.9.1</a>
        &gt;
        Launching Applications Using Docker Containers
        </div>
            <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://git-wip-us.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
            |
                <a href="http://hadoop.apache.org/" class="externalLink">Apache Hadoop</a>
              
                                   &nbsp;| Last Published: 2018-04-16
              &nbsp;| Version: 2.9.1
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CommandsManual.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Compatibility.html">Hadoop Compatibility</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/InterfaceClassification.html">Interface Classification</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Superusers.html">Proxy User</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/RackAwareness.html">Rack Awareness</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/CredentialProviderAPI.html">Credential Provider API</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">NameNode HA With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">NameNode HA With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/Hftp.html">HFTP</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">libhdfs (C API)</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS (REST API)</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-hdfs-httpfs/index.html">HttpFS</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Storage Policies</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">Memory Storage Support</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsUpgradeDomain.html">Upgrade Domain</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/HdfsDataNodeAdminGuide.html">DataNode Admin</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs-rbf/HDFSRouterFederation.html">Router Federation</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibility with 1.x</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/SharedCacheSupport.html">Support for YARN Shared Cache</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YARN.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeLabel.html">Node Labels</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html">Timeline Service V.2</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html">YARN Application Security</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManager.html">NodeManager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/DockerContainerExecutor.html">DockerContainerExecutor</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/DockerContainers.html">Running Applications in Docker Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">Using CGroups</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/SecureContainer.html">Secure Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/registry/index.html">Registry</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ReservationSystem.html">Reservation System</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/GracefulDecommission.html">Graceful Decommission</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/OpportunisticContainers.html">Opportunistic Containers</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/Federation.html">YARN Federation</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/SharedCache.html">Shared Cache</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html#Timeline_Server_REST_API_v1">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html#Timeline_Service_v.2_REST_API">Timeline Service V.2</a>
            </li>
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-aws/tools/hadoop-aws/index.html">Amazon S3</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-azure/index.html">Azure Blob Storage</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-openstack/index.html">OpenStack Swift</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-streaming/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-archives/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-archive-logs/HadoopArchiveLogs.html">Hadoop Archive Logs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-distcp/DistCp.html">DistCp</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-gridmix/GridMix.html">GridMix</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-rumen/Rumen.html">Rumen</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-resourceestimator/ResourceEstimator.html">Resource Estimator Service</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Benchmarking.html">Hadoop Benchmarking</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/release/index.html">Changelog and Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../api/index.html">API docs</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="./images/logos/maven-feather.png"/>
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!---
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--><h1>Launching Applications Using Docker Containers</h1>

<ul>
<li><a href="#Security_Warning">Security Warning</a></li>
<li><a href="#Overview">Overview</a></li>
<li><a href="#Cluster_Configuration">Cluster Configuration</a></li>
<li><a href="#Docker_Image_Requirements">Docker Image Requirements</a></li>
<li><a href="#Application_Submission">Application Submission</a></li>
<li><a href="#Connecting_to_a_Secure_Docker_Repository">Connecting to a Secure Docker Repository</a></li>
<li><a href="#Example:_MapReduce">Example: MapReduce</a></li>
<li><a href="#Example:_Spark">Example: Spark</a></li></ul>
<div class="section">
<h2><a name="Security_Warning"></a>Security Warning</h2>
<p><b>IMPORTANT</b> This feature is experimental and is not complete. <b>IMPORTANT</b> Enabling this feature and running Docker containers in your cluster has security implications. With this feature enabled, it may be possible to gain root access to the YARN NodeManager hosts. Given Docker&#x2019;s integration with many powerful kernel features, it is imperative that administrators understand <a class="externalLink" href="https://docs.docker.com/engine/security/security/">Docker security</a> before enabling this feature.</p></div>
<div class="section">
<h2><a name="Overview"></a>Overview</h2>
<p><a class="externalLink" href="https://www.docker.io/">Docker</a> combines an easy-to-use interface to Linux containers with easy-to-construct image files for those containers. In short, Docker enables users to bundle an application together with its preferred execution environment to be executed on a target machine. For more information about Docker, see their <a class="externalLink" href="http://docs.docker.com">documentation</a>.</p>
<p>The Linux Container Executor (LCE) allows the YARN NodeManager to launch YARN containers to run either directly on the host machine or inside Docker containers. The application requesting the resources can specify for each container how it should be executed. The LCE also provides enhanced security and is required when deploying a secure cluster. When the LCE launches a YARN container to execute in a Docker container, the application can specify the Docker image to be used.</p>
<p>Docker containers provide a custom execution environment in which the application&#x2019;s code runs, isolated from the execution environment of the NodeManager and other applications. These containers can include special libraries needed by the application, and they can have different versions of native tools and libraries including Perl, Python, and Java. Docker containers can even run a different flavor of Linux than what is running on the NodeManager.</p>
<p>Docker for YARN provides both consistency (all YARN containers will have the same software environment) and isolation (no interference with whatever is installed on the physical machine).</p>
<p>Docker support in the LCE is still evolving. To track progress, follow <a class="externalLink" href="https://issues.apache.org/jira/browse/YARN-3611">YARN-3611</a>, the umbrella JIRA for Docker support improvements.</p></div>
<div class="section">
<h2><a name="Cluster_Configuration"></a>Cluster Configuration</h2>
<p>The LCE requires that container-executor binary be owned by root:hadoop and have 6050 permissions. In order to launch Docker containers, the Docker daemon must be running on all NodeManager hosts where Docker containers will be launched. The Docker client must also be installed on all NodeManager hosts where Docker containers will be launched and able to start Docker containers.</p>
<p>To prevent timeouts while starting jobs, any large Docker images to be used by an application should already be loaded in the Docker daemon&#x2019;s cache on the NodeManager hosts. A simple way to load an image is by issuing a Docker pull request. For example:</p>

<div class="source">
<div class="source">
<pre>    sudo docker pull images/hadoop-docker:latest
</pre></div></div>
<p>The following properties should be set in yarn-site.xml:</p>

<div class="source">
<div class="source">
<pre>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.container-executor.class&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor&lt;/value&gt;
    &lt;description&gt;
      This is the container executor setting that ensures that all applications
      are started with the LinuxContainerExecutor.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.linux-container-executor.group&lt;/name&gt;
    &lt;value&gt;hadoop&lt;/value&gt;
    &lt;description&gt;
      The POSIX group of the NodeManager. It should match the setting in
      &quot;container-executor.cfg&quot;. This configuration is required for validating
      the secure access of the container-executor binary.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
    &lt;description&gt;
      Whether all applications should be run as the NodeManager process' owner.
      When false, applications are launched instead as the application owner.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.allowed-runtimes&lt;/name&gt;
    &lt;value&gt;default,docker&lt;/value&gt;
    &lt;description&gt;
      Comma separated list of runtimes that are allowed when using
      LinuxContainerExecutor. The allowed values are default and docker.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.docker.allowed-container-networks&lt;/name&gt;
    &lt;value&gt;host,none,bridge&lt;/value&gt;
    &lt;description&gt;
      Optional. A comma-separated set of networks allowed when launching
      containers. Valid values are determined by Docker networks available from
      `docker network ls`
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.docker.default-container-network&lt;/name&gt;
    &lt;value&gt;host&lt;/value&gt;
    &lt;description&gt;
      The network used when launching Docker containers when no
      network is specified in the request. This network must be one of the
      (configurable) set of allowed container networks.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
    &lt;description&gt;
      Optional. Whether applications are allowed to run in privileged
      containers.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.docker.privileged-containers.acl&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;
      Optional. A comma-separated list of users who are allowed to request
      privileged contains if privileged containers are allowed.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.runtime.linux.docker.capabilities&lt;/name&gt;
    &lt;value&gt;CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE&lt;/value&gt;
    &lt;description&gt;
      Optional. This configuration setting determines the capabilities
      assigned to docker containers when they are launched. While these may not
      be case-sensitive from a docker perspective, it is best to keep these
      uppercase. To run without any capabilites, set this value to
      &quot;none&quot; or &quot;NONE&quot;
    &lt;/description&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre></div></div>
<p>In addition, a container-executer.cfg file must exist and contain settings for the container executor. The file must be owned by root with permissions 0400. The format of the file is the standard Java properties file format, for example</p>

<div class="source">
<div class="source">
<pre>`key=value`
</pre></div></div>
<p>The following properties are required to enable Docker support:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Configuration Name </th>
      
<th align="left">Description </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left"><tt>yarn.nodemanager.linux-container-executor.group</tt> </td>
      
<td align="left">The Unix group of the NodeManager. It should match the yarn.nodemanager.linux-container-executor.group in the yarn-site.xml file. </td>
    </tr>
  </tbody>
</table>
<p>The container-executor.cfg must contain a section to determine the capabilities that containers are allowed. It contains the following properties:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Configuration Name </th>
      
<th align="left">Description </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left"><tt>module.enabled</tt> </td>
      
<td align="left">Must be &#x201c;true&#x201d; or &#x201c;false&#x201d; to enable or disable launching Docker containers respectively. Default value is 0. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>docker.binary</tt> </td>
      
<td align="left">The binary used to launch Docker containers. /usr/bin/docker by default. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>docker.allowed.capabilities</tt> </td>
      
<td align="left">Comma separated capabilities that containers are allowed to add. By default no capabilities are allowed to be added. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>docker.allowed.devices</tt> </td>
      
<td align="left">Comma separated devices that containers are allowed to mount. By default no devices are allowed to be added. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>docker.allowed.networks</tt> </td>
      
<td align="left">Comma separated networks that containers are allowed to use. If no network is specified when launching the container, the default Docker network will be used. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>docker.allowed.ro-mounts</tt> </td>
      
<td align="left">Comma separated directories that containers are allowed to mount in read-only mode. By default, no directories are allowed to mounted. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>docker.allowed.rw-mounts</tt> </td>
      
<td align="left">Comma separated directories that containers are allowed to mount in read-write mode. By default, no directories are allowed to mounted. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>docker.privileged-containers.enabled</tt> </td>
      
<td align="left">Set to 1 or 0 to enable or disable launching privileged containers. Default value is 0. </td>
    </tr>
  </tbody>
</table>
<p>Please note that if you wish to run Docker containers that require access to the YARN local directories, you must add them to the docker.allowed.rw-mounts list.</p>
<p>In addition, containers are not permitted to mount any parent of the container-executor.cfg directory in read-write mode.</p>
<p>The following properties are optional:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Configuration Name </th>
      
<th align="left">Description </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left"><tt>min.user.id</tt> </td>
      
<td align="left">The minimum UID that is allowed to launch applications. The default is no minimum </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>banned.users</tt> </td>
      
<td align="left">A comma-separated list of usernames who should not be allowed to launch applications. The default setting is: yarn, mapred, hdfs, and bin. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>allowed.system.users</tt> </td>
      
<td align="left">A comma-separated list of usernames who should be allowed to launch applications even if their UIDs are below the configured minimum. If a user appears in allowed.system.users and banned.users, the user will be considered banned. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>feature.tc.enabled</tt> </td>
      
<td align="left">Must be 0 or 1. 0 means traffic control commands are disabled. 1 means traffic control commands are allowed. </td>
    </tr>
  </tbody>
</table>
<p>Part of a container-executor.cfg which allows Docker containers to be launched is below:</p>

<div class="source">
<div class="source">
<pre>yarn.nodemanager.linux-container-executor.group=yarn
[docker]
  module.enabled=true
  docker.allowed.capabilities=SYS_CHROOT,MKNOD,SETFCAP,SETPCAP,FSETID,CHOWN,AUDIT_WRITE,SETGID,NET_RAW,FOWNER,SETUID,DAC_OVERRIDE,KILL,NET_BIND_SERVICE
  docker.allowed.networks=bridge,host,none
  docker.allowed.ro-mounts=/sys/fs/cgroup
  docker.allowed.rw-mounts=/var/hadoop/yarn/local-dir,/var/hadoop/yarn/log-dir

</pre></div></div></div>
<div class="section">
<h2><a name="Docker_Image_Requirements"></a>Docker Image Requirements</h2>
<p>In order to work with YARN, there are two requirements for Docker images.</p>
<p>First, the Docker container will be explicitly launched with the application owner as the container user. If the application owner is not a valid user in the Docker image, the application will fail. The container user is specified by the user&#x2019;s UID. If the user&#x2019;s UID is different between the NodeManager host and the Docker image, the container may be launched as the wrong user or may fail to launch because the UID does not exist.</p>
<p>Second, the Docker image must have whatever is expected by the application in order to execute. In the case of Hadoop (MapReduce or Spark), the Docker image must contain the JRE and Hadoop libraries and have the necessary environment variables set: JAVA_HOME, HADOOP_COMMON_PATH, HADOOP_HDFS_HOME, HADOOP_MAPRED_HOME, HADOOP_YARN_HOME, and HADOOP_CONF_DIR. Note that the Java and Hadoop component versions available in the Docker image must be compatible with what&#x2019;s installed on the cluster and in any other Docker images being used for other tasks of the same job. Otherwise the Hadoop components started in the Docker container may be unable to communicate with external Hadoop components.</p>
<p>If a Docker image has a <a class="externalLink" href="https://docs.docker.com/engine/reference/builder/#cmd">command</a> set, the behavior will depend on whether the <tt>YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE</tt> is set to true. If so, the command will be overridden when LCE launches the image with YARN&#x2019;s container launch script.</p>
<p>If a Docker image has an <a class="externalLink" href="https://docs.docker.com/engine/reference/builder/#entrypoint">entry point</a> set, the entry point will be honored, but the default command may be overridden, as just mentioned above. Unless the entry point is something similar to <tt>sh -c</tt> or <tt>YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE</tt> is set to true, the net result will likely be undesirable. Because the YARN container launch script is required to correctly launch the YARN task, use of entry points is discouraged.</p>
<p>If an application requests a Docker image that has not already been loaded by the Docker daemon on the host where it is to execute, the Docker daemon will implicitly perform a Docker pull command. Both MapReduce and Spark assume that tasks which take more that 10 minutes to report progress have stalled, so specifying a large Docker image may cause the application to fail.</p></div>
<div class="section">
<h2><a name="Application_Submission"></a>Application Submission</h2>
<p>Before attempting to launch a Docker container, make sure that the LCE configuration is working for applications requesting regular YARN containers. If after enabling the LCE one or more NodeManagers fail to start, the cause is most likely that the ownership and/or permissions on the container-executer binary are incorrect. Check the logs to confirm.</p>
<p>In order to run an application in a Docker container, set the following environment variables in the application&#x2019;s environment:</p>

<table border="0" class="bodyTable">
  <thead>
    
<tr class="a">
      
<th align="left">Environment Variable Name </th>
      
<th align="left">Description </th>
    </tr>
  </thead>
  <tbody>
    
<tr class="b">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_TYPE</tt> </td>
      
<td align="left">Determines whether an application will be launched in a Docker container. If the value is &#x201c;docker&#x201d;, the application will be launched in a Docker container. Otherwise a regular process tree container will be used. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_DOCKER_IMAGE</tt> </td>
      
<td align="left">Names which image will be used to launch the Docker container. Any image name that could be passed to the Docker client&#x2019;s run command may be used. The image name may include a repo prefix. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE</tt> </td>
      
<td align="left">Controls whether the Docker container&#x2019;s default command is overridden. When set to true, the Docker container&#x2019;s command will be &#x201c;bash <i>path_to_launch_script</i>&#x201d;. When unset or set to false, the Docker container&#x2019;s default command is used. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK</tt> </td>
      
<td align="left">Sets the network type to be used by the Docker container. It must be a valid value as determined by the yarn.nodemanager.runtime.linux.docker.allowed-container-networks property. </td>
    </tr>
    
<tr class="b">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_DOCKER_RUN_PRIVILEGED_CONTAINER</tt> </td>
      
<td align="left">Controls whether the Docker container is a privileged container. In order to use privileged containers, the yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed property must be set to true, and the application owner must appear in the value of the yarn.nodemanager.runtime.linux.docker.privileged-containers.acl property. If this environment variable is set to true, a privileged Docker container will be used if allowed. No other value is allowed, so the environment variable should be left unset rather than setting it to false. </td>
    </tr>
    
<tr class="a">
      
<td align="left"><tt>YARN_CONTAINER_RUNTIME_DOCKER_LOCAL_RESOURCE_MOUNTS</tt> </td>
      
<td align="left">Adds additional volume mounts to the Docker container. The value of the environment variable should be a comma-separated list of mounts. All such mounts must be given as &#x201c;source:dest&#x201d;, where the source is an absolute path that is not a symlink and that points to a localized resource. Note that as of YARN-5298, localized directories are automatically mounted into the container as volumes. </td>
    </tr>
  </tbody>
</table>
<p>The first two are required. The remainder can be set as needed. While controlling the container type through environment variables is somewhat less than ideal, it allows applications with no awareness of YARN&#x2019;s Docker support (such as MapReduce and Spark) to nonetheless take advantage of it through their support for configuring the application environment.</p>
<p>Once an application has been submitted to be launched in a Docker container, the application will behave exactly as any other YARN application. Logs will be aggregated and stored in the relevant history server. The application life cycle will be the same as for a non-Docker application.</p></div>
<div class="section">
<h2><a name="Connecting_to_a_Secure_Docker_Repository"></a>Connecting to a Secure Docker Repository</h2>
<p>Until YARN-5428 is complete, the Docker client command will draw its configuration from the default location, which is $HOME/.docker/config.json on the NodeManager host. The Docker configuration is where secure repository credentials are stored, so use of the LCE with secure Docker repos is discouraged until YARN-5428 is complete.</p>
<p>As a work-around, you may manually log the Docker daemon on every NodeManager host into the secure repo using the Docker login command:</p>

<div class="source">
<div class="source">
<pre>  docker login [OPTIONS] [SERVER]

  Register or log in to a Docker registry server, if no server is specified
  &quot;https://index.docker.io/v1/&quot; is the default.

  -e, --email=&quot;&quot;       Email
  -p, --password=&quot;&quot;    Password
  -u, --username=&quot;&quot;    Username
</pre></div></div>
<p>Note that this approach means that all users will have access to the secure repo.</p></div>
<div class="section">
<h2><a name="Example:_MapReduce"></a>Example: MapReduce</h2>
<p>To submit the pi job to run in Docker containers, run the following commands:</p>

<div class="source">
<div class="source">
<pre>    vars=&quot;YARN_CONTAINER_RUNTIME_TYPE=docker,YARN_CONTAINER_RUNTIME_DOCKER_IMAGE=hadoop-docker&quot;
    hadoop jar hadoop-examples.jar pi -Dyarn.app.mapreduce.am.env=$vars \
        -Dmapreduce.map.env=$vars -Dmapreduce.reduce.env=$vars 10 100
</pre></div></div>
<p>Note that the application master, map tasks, and reduce tasks are configured independently. In this example, we are using the hadoop-docker image for all three.</p></div>
<div class="section">
<h2><a name="Example:_Spark"></a>Example: Spark</h2>
<p>To run a Spark shell in Docker containers, run the following command:</p>

<div class="source">
<div class="source">
<pre>    spark-shell --master yarn --conf spark.executorEnv.YARN_CONTAINER_RUNTIME_TYPE=docker \
        --conf spark.executorEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE=hadoop-docker \
        --conf spark.yarn.AppMasterEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE=hadoop-docker \
        --conf spark.yarn.AppMasterEnv.YARN_CONTAINER_RUNTIME_TYPE=docker
</pre></div></div>
<p>Note that the application master and executors are configured independently. In this example, we are using the hadoop-docker image for both.</p></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2018
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
